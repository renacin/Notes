*Notes Taken From: Spark The Definitive Guide* - Bill Chambers, Matei Zaharia



==***1. Create A Spark Dataframe, & Query It

```
# Create 1000 Rows Under Column, Query It & Count Rows
myRange   = spark.range(1000).toDF("Number")
new_range = myRange.where("Number % 2 = 0 AND Number <= 20")
new_range.count()
```


==***2. Import A Spark Dataframe & Sort It By Customer Name

```
# Read A CSV Into A Spark Dataframe
flightData2015 = spark\
				.read
				.option("inferSchema", "true")\
				.option("header","true")\
				.csv("/data/flight-data/csv/2015-summary.csv")

# Sort By Customer Name
flightData2015.sort("Name")

# Represent As SQL Temp Table
flightData2015.createOrReplaceTempView("flight_data_2015")

```


==***3. Group Data & Count Numbers

```
# Read A CSV Into A Spark Dataframe
from pyspark.sql.functions import desc

flightData2015.groupBy("DEST_COUNTRY_NAME")\
		      .sum("count")\
              .withColumnRenamed("sum(count)","destination_total")\
              .sort(desc("destination_total"))\
              .limit(5)\
              .show()

```


from pyspark.sql.functions import lit
df.withColumn("numberOne", lit(1))

df.withColumnRenamed("DESTCOUNTRYNAME", "dest").columns

dfWithLongColName.drop("ORIGINCOUNTRY__NAME", "DESTCOUNTRY__NAME")

df.withColumn("count2", col("count").cast("long"))

df.printSchema()
df = spark.read.format("json").load("/data/flight-data/json/2015-summary.json")





# Initialize Spark session
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Spark Playground').getOrCreate()

# Load the customers.csv dataset
df = spark.read.format('csv').option('header', 'true').load('/samples/sales.csv')

# Change Column Type
df.withColumn("total_amount", col("total_amount").cast("double"))

# Group Data
df.groupBy("customer_id")\
  .sum("total_amount")\
  .withColumnRenamed("sum(total_amount)", "tot_spending")\
  .sort("tot_spending")\
  .show()

